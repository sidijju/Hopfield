program: main.py
project: language_model_benchmarks
method: grid

parameters:
  model:
    parameters:
      name:
        values: ["rnn", "linear_attention", "hopfield_attention"]
      dim:
        values: [128, 256]
      num_layers:
        values: [2, 4, 8]

  training:
    parameters:
      batch_size:
        values: [4, 8]
      epochs:
        values: [3, 5, 10]
      sequence_length:
        # values: [128, 256, 512, 1024, 2048, 4096, 8192]
        values : [1024]
      learning_rate:
        values: [1e-3, 5e-4]

  benchmark:
    parameters:
      name:
        values: ["lambada"]  # Can add more as implemented: ["lambada", "wikitext", "memory", "lra"]
