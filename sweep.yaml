program: main.py
project: language_model_benchmarks
method: grid

parameters:
  model:
    parameters:
      name:
        values: ["rnn", "linear_attention", "hopfield_attention"]
      dim:
        values: [128, 256]
      num_layers:
        values: [2, 4, 8]

  training:
    parameters:
      sequence_length:
        # values: [128, 256, 512, 1024, 2048, 4096, 8192]
        values : [1024]

  benchmark:
    parameters:
      name:
        values: ["lambada"]  # Can add more as implemented: ["lambada", "wikitext", "memcopy", "lra"]
